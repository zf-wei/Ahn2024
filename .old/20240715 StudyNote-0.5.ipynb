{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa63843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#隐藏警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c484120e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate an LFR Network and Draw it\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "\n",
    "n = 1000\n",
    "tau1 = 2  # Power-law exponent for the degree distribution\n",
    "tau2 = 1.1  # Power-law exponent for the community size distribution\n",
    "mu = 0.3  # Mixing parameter\n",
    "avg_deg = 25  # Average Degree\n",
    "max_deg = int(0.1 * n)  # Max Degree\n",
    "min_commu = 60  # Min Community Size\n",
    "max_commu = int(0.1 * n)  # Max Community Size\n",
    "\n",
    "#for mu in np.arange(0.1, 0.11, 0.1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd92eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network import *\n",
    "import numpy as np\n",
    "    \n",
    "import networkx as nx\n",
    "import scipy.sparse\n",
    "\n",
    "def to_networkx(self):\n",
    "    if isinstance(self.graph, scipy.sparse.csr.csr_matrix):\n",
    "        return nx.from_scipy_sparse_matrix(self.graph)\n",
    "    else:\n",
    "        return nx.from_numpy_array(self.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d4380c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 4 µs, total: 11 µs\n",
      "Wall time: 13.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This function takes the orthogonal part of G_sparse eigenvectors.\n",
    "# Hopefully, we will get a better community detection result from this treatment.\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def compute_orthogonal_components(G, V):\n",
    "    \"\"\"\n",
    "    Compute the component of each column of V orthogonal to the degree sequence vector of a graph.\n",
    "\n",
    "    Parameters:\n",
    "    G (networkx.classes.graph.Graph): The input graph.\n",
    "    V (numpy.ndarray): The input 2D array.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The component of each column of V orthogonal to the degree sequence vector of the graph.\n",
    "    \"\"\"\n",
    "    # get measure and constant vector\n",
    "    mu = np.array([d for n, d in G.degree()])\n",
    "    u = np.ones(G.number_of_nodes())\n",
    "\n",
    "    # \n",
    "    orthogonal_components = np.zeros_like(V)\n",
    "\n",
    "    # do orthogonal for each column\n",
    "    for i in range(V.shape[1]):\n",
    "        v = V[:, i]\n",
    "        orthogonal_component = v - ((v @ (u * mu)) / (u @ (u * mu))) * u\n",
    "        orthogonal_components[:, i] = orthogonal_component  # \n",
    "\n",
    "    return orthogonal_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e08c1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function for Laplacian Eigenmap using Cupy. The presence of GPU is required.\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import cupy as cp\n",
    "\n",
    "def lap_cupy(graph, dim):\n",
    "    \"\"\"\n",
    "    Compute the Laplacian embedding of a graph using CuPy.\n",
    "\n",
    "    Parameters:\n",
    "    graph (networkx.classes.graph.Graph): The input graph.\n",
    "    dim (int): The dimension of the embedding.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The Laplacian embedding of the graph.\n",
    "    \"\"\"\n",
    "    # Check inputs\n",
    "    assert isinstance(graph, nx.Graph), \"Input graph must be a NetworkX graph.\"\n",
    "    assert isinstance(dim, int) and dim > 0, \"Input dim must be a positive integer.\"\n",
    "    assert dim < graph.number_of_nodes(), \"Input dim must be less than the number of nodes in the graph.\"\n",
    "\n",
    "    # Convert the adjacency matrix of the graph to a CuPy array\n",
    "    A = cp.asarray(nx.adjacency_matrix(graph, nodelist=graph.nodes(), weight='weight').toarray(), dtype=cp.float64)\n",
    "\n",
    "    # Compute L1 normalization along axis 1 (rows)\n",
    "    row_sums = cp.linalg.norm(A, ord=1, axis=1)\n",
    "    A /= row_sums.reshape(-1, 1)\n",
    "\n",
    "    # Compute the eigenvalues and eigenvectors of I_n - A\n",
    "    I_n = cp.eye(graph.number_of_nodes())\n",
    "    w, v = cp.linalg.eigh(I_n - A)\n",
    "\n",
    "    # Sort the eigenvectors by the real part of the eigenvalues\n",
    "    v = v[:, cp.argsort(w.real)]\n",
    "\n",
    "    # Return the embedding\n",
    "    return v[:, 1:(dim+1)].get().real  # Explicitly convert to NumPy array using .get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64ff718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### KMeans Clustering using Euclidean and Spherical metrics\n",
    "### Using NMI and ECSim for comparison\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import clusim.sim as sim\n",
    "from clusim.clustering import Clustering\n",
    "\n",
    "\n",
    "def euclid_membership(K, points):\n",
    "    euc_kmeans = KMeans(n_clusters=K, n_init=10)\n",
    "    euc_kmeans.fit(points)\n",
    "\n",
    "    evala_euclid_membership = euc_kmeans.labels_\n",
    "    return evala_euclid_membership\n",
    "\n",
    "def cosine_membership(K, points):\n",
    "    normalized_points = normalize(points)\n",
    "    cos_kmeans = KMeans(n_clusters=K, n_init=10)\n",
    "    cos_kmeans.fit(normalized_points)\n",
    "\n",
    "    evala_cosine_membership = cos_kmeans.labels_\n",
    "    return evala_cosine_membership\n",
    "\n",
    "def calculate_score(evala, intr_list, K):\n",
    "# evala is the embedding vectors\n",
    "# intr_list is the intrinsic community strucuture\n",
    "# K is the number of clusters in Kmeans\n",
    "    return_val = [] # 首先准备好返回值 \n",
    "\n",
    "    intr_clus = Clustering({i: [intr_list[i]] for i in range(len(intr_list))})\n",
    "\n",
    "    evala_euclid_membership = euclid_membership(K, evala)\n",
    "\n",
    "    evala_cosine_membership = cosine_membership(K, evala)\n",
    "\n",
    "    ## compare with intrinsic community structure using NMI\n",
    "    return_val.append(normalized_mutual_info_score(evala_euclid_membership, intr_list, average_method='arithmetic'))\n",
    "    return_val.append(normalized_mutual_info_score(evala_cosine_membership, intr_list, average_method='arithmetic'))\n",
    "    \n",
    "    \n",
    "    evala_euclid_clustering = Clustering(elm2clu_dict={i: [evala_euclid_membership[i]] for i in range(len(evala_euclid_membership))})\n",
    "    evala_cosine_clustering = Clustering(elm2clu_dict={i: [evala_cosine_membership[i]] for i in range(len(evala_cosine_membership))})\n",
    "    \n",
    "    ## compare with intrinsic community structure using ECSim\n",
    "    evala_euclid_similarity = sim.element_sim(intr_clus, evala_euclid_clustering, alpha=0.9)\n",
    "    evala_cosine_similarity = sim.element_sim(intr_clus, evala_cosine_clustering, alpha=0.9)\n",
    "    return_val.append(evala_euclid_similarity)\n",
    "    return_val.append(evala_cosine_similarity)\n",
    "    \n",
    "    return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee8fc3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1] 0\n",
      "[1, 1, 1, 1] 1\n",
      "[1, 1, 1, 1] 2\n",
      "[2, 2, 2, 2] 3\n",
      "[2, 2, 2, 2] 4\n",
      "[2, 3, 2, 3] 5\n",
      "[3, 4, 3, 4] 6\n",
      "[4, 4, 4, 4] 7\n",
      "[4, 5, 4, 5] 8\n",
      "[4, 5, 5, 5] 9\n",
      "[4, 6, 5, 6] 10\n",
      "[4, 7, 6, 7] 11\n",
      "[4, 7, 6, 7] 12\n",
      "[4, 8, 6, 8] 13\n",
      "[4, 9, 6, 9] 14\n",
      "[4, 10, 6, 10] 15\n",
      "[5, 10, 7, 10] 16\n",
      "[6, 11, 8, 10] 17\n",
      "[6, 11, 8, 10] 18\n",
      "[6, 12, 8, 11] 19\n",
      "[6, 13, 8, 12] 20\n",
      "[6, 13, 9, 12] 21\n",
      "[6, 13, 9, 12] 22\n",
      "[7, 14, 10, 13] 23\n",
      "[7, 15, 10, 14] 24\n",
      "[8, 15, 11, 14] 25\n",
      "[9, 16, 12, 15] 26\n",
      "[10, 17, 13, 16] 27\n",
      "[11, 17, 14, 16] 28\n",
      "[11, 17, 14, 16] 29\n",
      "[12, 18, 15, 17] 30\n",
      "[12, 19, 15, 18] 31\n",
      "[13, 20, 16, 19] 32\n",
      "[14, 20, 17, 19] 33\n",
      "[15, 20, 18, 20] 34\n",
      "[16, 21, 19, 21] 35\n",
      "[16, 22, 19, 22] 36\n",
      "[17, 23, 20, 23] 37\n",
      "[17, 23, 20, 23] 38\n",
      "[17, 23, 20, 23] 39\n",
      "[17, 23, 20, 23] 40\n",
      "[17, 23, 20, 23] 41\n",
      "[18, 23, 21, 24] 42\n",
      "[19, 24, 22, 25] 43\n",
      "[19, 25, 22, 26] 44\n",
      "[19, 25, 22, 26] 45\n",
      "[19, 25, 22, 26] 46\n",
      "[20, 25, 23, 26] 47\n",
      "[21, 26, 24, 27] 48\n",
      "[21, 27, 24, 28] 49\n"
     ]
    }
   ],
   "source": [
    "K = 15\n",
    "\n",
    "stat = [0, 0, 0, 0]\n",
    "for i in range(50):\n",
    "    G = LFR_benchmark_graph(\n",
    "    n, tau1, tau2, mu, average_degree=avg_deg, max_degree=max_deg, min_community=min_commu, max_community=max_commu,\n",
    "    seed=7\n",
    "    )\n",
    "\n",
    "    # Remove multi-edges and self-loops from G\n",
    "    G = nx.Graph(G)\n",
    "    selfloop_edges = list(nx.selfloop_edges(G))\n",
    "    G.remove_edges_from(selfloop_edges)\n",
    "    \n",
    "    # LFR 图是有内在的社群结构的，每个节点的社群存储在其 community 属性中，是一个 set\n",
    "    # 通过运行循环，按照内在的社群结构给每个节点一个标签 即为其 intrinsic_membership\n",
    "    # 为了方便 intrinsic_membership 一开始是作为一个 dict 存储的，后来将其转化为一个 list\n",
    "    intrinsic_communities = {frozenset(G.nodes[v][\"community\"]) for v in G}\n",
    "    intrinsic_membership = {}\n",
    "    for node in range(G.number_of_nodes()):\n",
    "        for index, inner_set in enumerate(intrinsic_communities):\n",
    "            if node in inner_set:\n",
    "                intrinsic_membership[node] = index\n",
    "                break\n",
    "    intrinsic_membership = list(intrinsic_membership.values())\n",
    "    \n",
    "    # Get the edge list and edge weights and transform G from NetworkX to Network\n",
    "\n",
    "    # Get edge list as a numpy array\n",
    "    edge_list = list(G.edges())\n",
    "    edge_list = np.array(edge_list)\n",
    "\n",
    "    # Get edge weights as a numpy array\n",
    "    edge_weights = nx.get_edge_attributes(G, 'weight')\n",
    "    edge_weights = np.array(edge_weights)\n",
    "\n",
    "    edge_weights = [edge_weights[edge] if edge in edge_weights else 1 for edge in edge_list]\n",
    "\n",
    "    Gn = Network(edge_list, edge_weights)\n",
    "    # Gn is the representation of G in Network format\n",
    "\n",
    "    # Calculate effective resistance\n",
    "    epsilon=0.1\n",
    "    method='spl'\n",
    "    Effective_R = Gn.effR(epsilon, method)\n",
    "\n",
    "    # spectral sparse version of G in Network format\n",
    "    q = 10000\n",
    "    seed = 2020\n",
    "    Gn_Sparse = Gn.spl(q, Effective_R, seed=2020)\n",
    "\n",
    "\n",
    "\n",
    "    # G_sparse is the spectral sparse version of G in NetworkX format    \n",
    "    G_sparse = to_networkx(Gn_Sparse)\n",
    "    # check whether the sparse version is connected or not\n",
    "    nx.is_connected(G_sparse)\n",
    "    \n",
    "    score_sparse_orth = calculate_score(\n",
    "        compute_orthogonal_components(G, lap_cupy(G_sparse,K)),intrinsic_membership, len(np.unique(intrinsic_membership)))\n",
    "\n",
    "    score_sparse = calculate_score(lap_cupy(G_sparse,K),intrinsic_membership, len(np.unique(intrinsic_membership)))\n",
    "\n",
    "    score_original = calculate_score(lap_cupy(G,K),intrinsic_membership, len(np.unique(intrinsic_membership)))\n",
    "    \n",
    "    ratio_sparse_ortho = [a / b for a, b in zip(score_sparse_orth, score_original)]\n",
    "    ratio_sparse = [a / b for a, b in zip(score_sparse, score_original)]\n",
    "\n",
    "    for k in range(4):\n",
    "        if ratio_sparse_ortho[k]>ratio_sparse[k]:\n",
    "            stat[k] = stat[k]+1\n",
    "    print(stat, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb5bc8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42, 0.54, 0.48, 0.56]\n"
     ]
    }
   ],
   "source": [
    "result = [x / 50 for x in stat]\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
